{
  "hash": "7973e4f3bde9aedb9671117f28e4344f",
  "result": {
    "markdown": "---\ntitle: \"PPC: Ordinal predictions\"\nsubtitle: \"Bayesian network model for predicting the number of pregnancies in an IVF treatment.\"\ndate: \"2023-02-01\"\ndate-modified: \"2023-02-13\"\nauthor: \"Teemu SÃ¤ilynoja\"\nimage: \"../../docs/case_studies/ordinal/bn_classifier_files/figure-html/ppc_bars-1.svg\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-tools: true\n    code-line-numbers: true\n    default-image-extension: svg\n    fig-format: svg\n\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(cmdstanr)\nlibrary(DirichletReg)\nlibrary(bayesplot)\nlibrary(ggplot2)\nlibrary(reliabilitydiag)\nlibrary(khroma)\n\n# Source for the modified reliability plot\nsource(\"../../code/helpers.R\")\n\ngood_theme <- bayesplot::theme_default(base_family = \"Sans\") + theme(\n  axis.text = element_text(colour = \"#666666\", size = 12),\n  axis.ticks = element_line(colour = \"#666666\"),\n  title = element_text(colour = \"#666666\", size = 16),\n  plot.subtitle = element_text(colour = \"#666666\", size = 14),\n  legend.text = element_text(colour = \"#666666\", size = 12),\n  legend.title = element_text(colour = \"#666666\", size = 14),\n  axis.line = element_line(colour = \"#666666\"))\n\ntheme_set(good_theme)\nbayesplot_theme_set(good_theme)\ncolor_scheme_set(scheme = c(unname(colour(\"vibrant\")(7)[c(3,2,5,4,1,6)])))\n\nscale_colour_discrete = scale_colour_vibrant\nscale_fill_discrete = scale_fill_vibrant\n\nSEED <- 236543\nset.seed(SEED)\nSAVE_FITS = TRUE\nSIM_IIRM = TRUE # whether to use the inferred parameter values from the paper.\n```\n:::\n\n\n# Data generation\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstandata <- list()\nstandata$P = 0\nwhile(max(standata$P) < 3) {\n  pA = c(rdirichlet(1, rep(3, 3)))\n  if (SIM_IIRM == TRUE) {\n    pU = c(.78, .58, .26) # IIRM value from paper\n  } else {\n    pU = sort(runif(3), decreasing = T)\n  }\n  pS = c(rdirichlet(1, rep(3 , 4)))\n  if (SIM_IIRM == TRUE) {\n    pE = c(0, .07, .21, .39)# IIRM value from paper\n  } else {\n    pE = c(0, sort(runif(3)))\n  }\n  N <- 388\n  standata$N = N\n  standata$A = sample(1:3, size = N, replace = T, prob = pA)\n  standata$S = t(replicate(n = N, sample(1:4, size = 3, replace = T, prob = pS)))\n  standata$P = sapply(1:N, function(n) rbinom(1,1, pU[standata$A[n]]) * sum(rbinom(3,1, pE[standata$S[n, ]])))\n}\n```\n:::\n\n\n# Bayesian network model\nStan implementation of the BN model introduced in the paper. In short, the number of pregnancies is modeled to be equal to the number of viable embryos, $e$, if the uterus is receptive, $u$.\nThe observed variables are the patient age, $A$ split to 3 age categories, and the quality of the transferred embryo, $S \\in \\{1,\\dots,4\\}$, where $1$ means no transfer and categories $2$ to $4$ are in a ascending order based on quality.\n\n$$\nP = \\mathbb I(U = u)\\sum_{i=1}^3\\mathbb I(E_i = e),\n$$\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel <- cmdstan_model(stan_file = \"../../code/stan-models/bn_classifier.stan\")\nmodel\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ndata {\n  int N;\n  array[N] int A;\n  array[N, 3] int S;\n  array[N] int P;\n}\n\nparameters {\n  simplex[3] pA;\n  simplex[4] pS;\n  vector<lower=0, upper = 1>[3] pU;\n  vector<lower=0, upper = 1>[3] pE_;\n}\n\ntransformed parameters {\n  vector<lower=0, upper = 1>[4] pE;\n  pE[1] = 0;\n  pE[2:4] = pE_;\n}\n\nmodel {\n  // Priors\n  pA ~ dirichlet(rep_vector(1.0/3, 3));\n  pS ~ dirichlet(rep_vector(.25, 4));\n  pU ~ beta(1,1);\n  pE_ ~ beta(1,1);\n\n  // Likelihood\n  for (n in 1:N) {\n    target += categorical_lpmf(A[n] | pA);\n    target += categorical_lpmf(S[n,] | pS);\n  }\n\n  for (n in 1:N) {\n    if (P[n] > 0) {\n      target += log(pU[A[n]]);\n      if (P[n] == 1) {\n        target += log(\n          pE[S[n,1]] * (1 - pE[S[n,2]]) * (1 - pE[S[n,3]]) +\n          (1 - pE[S[n,1]]) * pE[S[n,2]] * (1 - pE[S[n,3]]) +\n          (1 - pE[S[n,1]]) * (1 - pE[S[n,2]]) * pE[S[n,3]]\n        );\n      }\n      if (P[n] == 2) {\n        target += log(\n          pE[S[n,1]] * pE[S[n,2]] * (1 - pE[S[n,3]]) +\n          (1 - pE[S[n,1]]) * pE[S[n,2]] * pE[S[n,3]] +\n          pE[S[n,1]] * (1 - pE[S[n,2]]) * pE[S[n,3]]\n        );\n      }\n      if (P[n] == 3) {\n        target += log(pE[S[n,1]] * pE[S[n,2]] * pE[S[n,3]]);\n      }\n    } else {\n      target += log(\n        1 - pU[A[n]] * (\n          pE[S[n,1]] * (1 - pE[S[n,2]]) * (1 - pE[S[n,3]]) +\n          (1 - pE[S[n,1]]) * pE[S[n,2]] * (1 - pE[S[n,3]]) +\n          (1 - pE[S[n,1]]) * (1 - pE[S[n,2]]) * pE[S[n,3]] +\n          pE[S[n,1]] * pE[S[n,2]] * (1 - pE[S[n,3]]) +\n          (1 - pE[S[n,1]]) * pE[S[n,2]] * pE[S[n,3]] +\n          pE[S[n,1]] * (1 - pE[S[n,2]]) * pE[S[n,3]] +\n          pE[S[n,1]] * pE[S[n,2]] * pE[S[n,3]]\n        )\n      );\n    }\n  }\n}\n\ngenerated quantities {\n  array[N] vector[4] ppm;\n  vector[N] yrep;\n\n  for (n in 1:N) {\n    ppm[n, 1] = 1 - pU[A[n]] * (\n          pE[S[n,1]] * (1 - pE[S[n,2]]) * (1 - pE[S[n,3]]) +\n          (1 - pE[S[n,1]]) * pE[S[n,2]] * (1 - pE[S[n,3]]) +\n          (1 - pE[S[n,1]]) * (1 - pE[S[n,2]]) * pE[S[n,3]] +\n          pE[S[n,1]] * pE[S[n,2]] * (1 - pE[S[n,3]]) +\n          (1 - pE[S[n,1]]) * pE[S[n,2]] * pE[S[n,3]] +\n          pE[S[n,1]] * (1 - pE[S[n,2]]) * pE[S[n,3]] +\n          pE[S[n,1]] * pE[S[n,2]] * pE[S[n,3]]\n        );\n    ppm[n, 2] = pU[A[n]] * (\n      pE[S[n,1]] * (1 - pE[S[n,2]]) * (1 - pE[S[n,3]]) +\n      (1 - pE[S[n,1]]) * pE[S[n,2]] * (1 - pE[S[n,3]]) +\n      (1 - pE[S[n,1]]) * (1 - pE[S[n,2]]) * pE[S[n,3]]\n      );\n    ppm[n, 3] = pU[A[n]] * (\n      pE[S[n,1]] * pE[S[n,2]] * (1 - pE[S[n,3]]) +\n          (1 - pE[S[n,1]]) * pE[S[n,2]] * pE[S[n,3]] +\n          pE[S[n,1]] * (1 - pE[S[n,2]]) * pE[S[n,3]]\n    );\n    ppm[n, 4] = pU[A[n]] * (pE[S[n,1]] * pE[S[n,2]] * pE[S[n,3]]);\n\n    yrep[n] = categorical_rng(ppm[n, ]);\n  }\n}\n```\n:::\n:::\n\n\nThe model samples very quickly with no apparent issues during the sampling process.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- model$sample(data = standata,\n                    parallel_chains = 4,\n                    refresh = 0,\n                    seed = SEED)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRunning MCMC with 4 parallel chains...\n\nChain 1 finished in 24.7 seconds.\nChain 3 finished in 25.2 seconds.\nChain 2 finished in 26.3 seconds.\nChain 4 finished in 26.7 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 25.7 seconds.\nTotal execution time: 27.1 seconds.\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compute the posterior means of the predictive probability mass of each case\nppm <- matrix(colMeans(fit$draws(variables = \"ppm\", format = \"matrix\")), ncol = 4)\n```\n:::\n\n\n# Posterior predictive checks\n\nA crude visualization of the posterior frequency of each case with 90% posterior predictive intervals. \n\n::: {.cell}\n\n```{.r .cell-code}\nppc_bars(y = standata$P,\n         yrep = fit$draws(variables = \"yrep\", format = \"matrix\") - 1,\n         prob = .9,\n         freq = F)\n```\n\n::: {.cell-output-display}\n![](bn_classifier_files/figure-html/ppc_bars-1.svg)\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_dotted_reliabilitydiag(x = pmin(1, rowSums(ppm[,-1])),\n                y = as.numeric(standata$P != 0), quantiles = 50) +\n  labs(title = \"Calibration: P >= 1\")\n```\n\n::: {.cell-output-display}\n![](bn_classifier_files/figure-html/reldiag_1-1.svg)\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_dotted_reliabilitydiag(x = pmin(1, rowSums(ppm[,-c(1,2)])),\n                y = as.numeric(standata$P > 1), quantiles = 50) +\n  labs(title = \"Calibration: P >= 2\")\n```\n\n::: {.cell-output-display}\n![](bn_classifier_files/figure-html/reldiag_2-1.svg)\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_dotted_reliabilitydiag(x = pmin(1, ppm[,c(4)]), y = as.numeric(standata$P == 3), quantiles = 20) +\n  labs(title = \"Calibration: P = 3\")\n```\n\n::: {.cell-output-display}\n![](bn_classifier_files/figure-html/reldiag_3-1.svg)\n:::\n:::\n\n\n\n# Marginal posteriors\n\n## Parameters of interest\n\n::: {.cell}\n\n```{.r .cell-code}\ncolor_scheme_set(scheme = color(\"BuRd\")(13)[6:1])\nmcmc_areas(fit$draws(variables = \"pU\", format = \"matrix\")) + vline_at(v = pU, colour = \"#666666\")\n```\n\n::: {.cell-output-display}\n![](bn_classifier_files/figure-html/mcmc_areas_pU-1.svg)\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmcmc_areas(fit$draws(variables = \"pE\", format = \"matrix\")[,-1]) + vline_at(v = pE[-1], colour = \"#666666\")\n```\n\n::: {.cell-output-display}\n![](bn_classifier_files/figure-html/mcmc_areas_pE-1.svg)\n:::\n:::\n\n\n\n## Population parameters\n\nFor some reason, the authors also model the frequencies of the different\nobservation categories in the population. These are recovered quite well.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmcmc_areas(fit$draws(variables = \"pA\", format = \"matrix\")) + vline_at(v = pA, colour = \"#666666\")\n```\n\n::: {.cell-output-display}\n![](bn_classifier_files/figure-html/mcmc_areas_pA-1.svg)\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmcmc_areas(fit$draws(variables = \"pS\", format = \"matrix\")) + vline_at(v = pS, colour = \"#666666\")\n```\n\n::: {.cell-output-display}\n![](bn_classifier_files/figure-html/mcmc_areas_pS-1.svg)\n:::\n:::\n",
    "supporting": [
      "bn_classifier_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}