[
  {
    "objectID": "case_studies/ordinal/ordinal.html",
    "href": "case_studies/ordinal/ordinal.html",
    "title": "Calibrarion of Ordinal Posterior Predictions",
    "section": "",
    "text": "Imports & options\nlibrary(\"bayesplot\")\nlibrary(\"cmdstanr\")\nlibrary(\"ggplot2\")\nlibrary(\"khroma\")\nlibrary(\"quartoExtra\")\n\n\n# Source for the modified reliability plot\nsource(\"../../code/helpers.R\")\n\ngood_theme <- bayesplot::theme_default(base_family = \"Sans\") + theme(\n  axis.text = element_text(colour = \"#666666\", size = 12),\n  axis.ticks = element_line(colour = \"#666666\"),\n  title = element_text(colour = \"#666666\", size = 16),\n  plot.subtitle = element_text(colour = \"#666666\", size = 14),\n  legend.text = element_text(colour = \"#666666\", size = 12),\n  legend.title = element_text(colour = \"#666666\", size = 14),\n  axis.line = element_line(colour = \"#666666\"))\n\ntheme_set(good_theme)\nbayesplot_theme_set(good_theme)\ncolor_scheme_set(scheme = c(unname(colour(\"vibrant\")(7)[c(3,2,5,4,1,6)])))\n\nscale_colour_discrete = scale_colour_vibrant\nscale_fill_discrete = scale_fill_vibrant\n\n\n# darkmode_theme_set(\n#     dark = ggthemes::theme_stata(scheme = \"s1rcolor\"),\n#     light = ggthemes::theme_stata(scheme = \"s1color\")\n# )\n\n\nSEED <- 236543\nset.seed(SEED)\nSAVE_FITS = TRUE\nThis notebook highlights posterior predictive visualizations when the posterior predictive distribution is ordinal.\nAs shown below, the ordinal nature of the predictions allows us to use the cumulative posterior predictive mass function to assess the calibration of the posterior."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Case Studies in Visual Posterior Predictive Checks",
    "section": "",
    "text": "Continuous Predictive Distribution\n\n\nShould I use a KDE?\n\n\n\n\n\n\n\n\n\nFeb 13, 2023\n\n\nTeemu S채ilynoja\n\n\n\n\n\n\n  \n\n\n\n\nCalibrarion of Ordinal Posterior Predictions\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 4, 2023\n\n\nTeemu S채ilynoja\n\n\n\n\n\n\n  \n\n\n\n\nPPC: Ordinal predictions\n\n\nBayesian network model for predicting the number of pregnancies in an IVF treatment.\n\n\n\n\n\n\n\n\n\nFeb 1, 2023\n\n\nTeemu S채ilynoja\n\n\n\n\n\n\n  \n\n\n\n\nPPC Visualizations for Categorical Data\n\n\nPalmer Penguins\n\n\nCalibration plots for the easy tasks of identifying penguin species in the Palmer Penguins data set.\n\n\n\n\n\n\nJan 30, 2023\n\n\nTeemu S채ilynoja\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "case_studies/categorical/categorical_palmer_penguins.html",
    "href": "case_studies/categorical/categorical_palmer_penguins.html",
    "title": "PPC Visualizations for Categorical Data",
    "section": "",
    "text": "Code\nlibrary(\"bayesplot\")\nlibrary(\"cmdstanr\")\nlibrary(\"ggplot2\")\nlibrary(\"khroma\")\nlibrary(\"quartoExtra\")\n\n\n# Source for the modified reliability plot\nsource(\"../../code/helpers.R\")\n\ngood_theme <- bayesplot::theme_default(base_family = \"Sans\") + theme(\n  axis.text = element_text(colour = \"#666666\", size = 12),\n  axis.ticks = element_line(colour = \"#666666\"),\n  title = element_text(colour = \"#666666\", size = 16),\n  plot.subtitle = element_text(colour = \"#666666\", size = 14),\n  legend.text = element_text(colour = \"#666666\", size = 12),\n  legend.title = element_text(colour = \"#666666\", size = 14),\n  axis.line = element_line(colour = \"#666666\"))\n\ntheme_set(good_theme)\nbayesplot_theme_set(good_theme)\ncolor_scheme_set(scheme = c(unname(colour(\"vibrant\")(7)[c(3,2,5,4,1,6)])))\n\nscale_colour_discrete = scale_colour_vibrant\nscale_fill_discrete = scale_fill_vibrant\n\nsource(\"../../code/helpers.R\")\n\nSAVE_MODEL = TRUE\n\n\nCalibration plots for the easy tasks of identifying penguin species in the Palmer Penguins data set.\n\nThe data\n\n\nCode\nif (FALSE) {\n  data(\"iris\")\n  X <- dplyr::select(na.omit(iris), -c(\"Species\"))\n  y <- as.numeric(iris$Species)\n} else {\n  library(palmerpenguins)\n  data(\"penguins\")\n  X <- na.omit(penguins)[, c(3,4,5,6)]\n  y <- as.factor(na.omit(penguins)$species)\n}\n\n\n\n\nCode\nggplot(X, aes(x = bill_length_mm, y = bill_depth_mm, colour = y)) +\n  geom_point() +\n  xlab(\"Bill length (mm)\") +\n  ylab(\"Bill depth (mm)\") +\n  labs(colour = \"Species\") +\n  legend_move(position = \"top\")\n\n\n\n\n\n\n\nThe model\n\n\nCode\nif (FALSE) {\n  # model directory contains the required model\n  # load precompiled model\n} else {\n  model_code  = \"\n  data {\n    int N; // number of observations\n    int D; // number of features\n    int N_classes; // number of classes\n    matrix [N, D] X; // observation data\n    array[N] int <lower = 1, upper = N_classes> y; // target values {1,..., N_classes}\n  }\n  \n  transformed data {\n    matrix[D + 1, N] X_stn;\n    X_stn[D + 1, ] = rep_row_vector(1, N);\n    for (d in 1:D) {\n      X_stn[d,] = to_row_vector((X[, d] - mean(X[, d])) / sd(X[, d]));\n    }\n  }\n  \n  parameters {\n    matrix[N_classes, D + 1] W;\n  }\n  \n  transformed parameters {\n    matrix[N_classes, N] Beta;\n    for (c in 1:N_classes) {\n      Beta[c, ] =  W[c, ] * X_stn;\n    }\n  }\n  \n  model {\n    for (d in 1:(D + 1)) {\n      for (c in 1:N_classes) {\n        target += normal_lpdf(W[c, d] | 0, 1);\n      }\n    }\n    for (n in 1:N) {\n      target += categorical_logit_lpmf(y[n] | Beta[,n]);\n    }\n  }\n  \n  generated quantities {\n    vector[N] yrep;\n    for (n in 1:N) {\n      yrep[n] = categorical_logit_rng(Beta[,n]);\n    }\n    matrix[N,N_classes] lpd;\n    for (n in 1:N) {\n      for (c in 1:N_classes) {\n        lpd[n, c] = categorical_logit_lpmf(c | Beta[,n]);\n      }\n    }\n  }\n  \"\n  model = cmdstan_model(write_stan_file(\n      model_code,\n      dir = if(SAVE_MODEL) \"../../code/stan-models\" else tempdir(),\n      basename = \"penguins_glm\",\n    ))\n}\n\n\n\n\nCode\nfit <- model$sample(\n  data = list(N = nrow(X),\n              D = ncol(X),\n              N_classes = length(unique(y)),\n              X = X,\n              y = as.numeric(y)),\n  parallel_chains = 4,\n  refresh = 0)\n\n\nRunning MCMC with 4 parallel chains...\n\nChain 1 finished in 5.9 seconds.\nChain 4 finished in 5.9 seconds.\nChain 3 finished in 6.2 seconds.\nChain 2 finished in 6.4 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 6.1 seconds.\nTotal execution time: 6.5 seconds.\n\n\n\n\nThe calibration\nThe common approach of plotting a bar char of the observations overlaid with posterior means and 95% confidence intervals only gives a crude idea of the calibration of the model predictions.\n\n\nCode\nppc_bars(as.numeric(y), fit$draws(variables = \"yrep\", format = \"matrix\")) +\n  scale_x_continuous(breaks = 1:3, labels = levels(y))\n\n\n\n\n\n\n\nCode\nplot_dotted_reliabilitydiag(x = exp(colMeans(fit$draws(variables = paste(paste(\"lpd[\", 1:nrow(X), sep=\"\"), \",1]\", sep=\"\"), format = \"matrix\"))), y = as.numeric(y == levels(y)[1]), quantiles = 20) + labs(title = paste(\"Calibration:\", levels(y)[1], \"vs. Others\"))\n\n\n\n\n\n\n\nCode\nplot_dotted_reliabilitydiag(x = exp(colMeans(fit$draws(variables = paste(paste(\"lpd[\", 1:nrow(X), sep=\"\"), \",2]\", sep=\"\"), format = \"matrix\"))), y = as.numeric(y == levels(y)[2]), quantiles = 20) + labs(title = paste(\"Calibration:\", levels(y)[2], \"vs. Others\"))\n\n\n\n\n\n\n\nCode\nplot_dotted_reliabilitydiag(x = exp(colMeans(fit$draws(variables = paste(paste(\"lpd[\", 1:nrow(X), sep=\"\"), \",3]\", sep=\"\"), format = \"matrix\"))), y = as.numeric(y == levels(y)[3]), quantiles = 20)  + labs(title = paste(\"Calibration:\", levels(y)[3], \"vs. Others\"))"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "case_studies/ordinal/ordinal.html#data-set",
    "href": "case_studies/ordinal/ordinal.html#data-set",
    "title": "Calibrarion of Ordinal Posterior Predictions",
    "section": "Data set",
    "text": "Data set\nBelow, I use synthetic data generated from observations from \\(K\\) Gaussians with varying means.\n\\[\\begin{align}\nx_n &\\sim \\mathcal N\\!\\!\\left(k, 0.5^2\\right), &\\text{for } n \\in\\{1,\\dots,N\\}\\\\\nk &\\sim \\text{Categorical}(\\theta_k),&\\\\\n\\theta_k &= \\frac 1 K, &\\text{for } k \\in \\{1, \\dots, K\\}.\n\\end{align}\\]\n\n\nData generation\nK <- 5\nN <- 1500\nsigma <- .5\nc <- sample(1:K, N, replace = T)\nx <- rnorm(N, c, sigma)\nstandata_gmm <- list(K = K,\n                     N = N,\n                     x = x,\n                     y = c,\n                     sigma = sigma)\n\n\n\n\nCode\nggplot(data.frame(standata_gmm)) +\n  geom_density(aes(x = x,\n                   colour = as.factor(y),\n                   fill = as.factor(y),\n                   group = as.factor(y)), alpha = .5) +\n  legend_none() +\n  xlab(\"\") + ylab(\"\") + ggtitle(paste(\"The data\", sep = \"\"))"
  },
  {
    "objectID": "case_studies/ordinal/ordinal.html#model",
    "href": "case_studies/ordinal/ordinal.html#model",
    "title": "Calibrarion of Ordinal Posterior Predictions",
    "section": "Model",
    "text": "Model\nThe data is fit with two models, both structured to first normalize the data and then fit a GMM with K = 5`\n\n\nRead model code\ngmm <- cmdstan_model(\"../../code/stan-models/gmm_classifier.stan\")\ngmm\n\n\ndata {\n  int<lower=2> K;                   // Number of classes\n  int<lower=0> N;                   // Total number of observations\n  array[N] int<lower=1, upper=K> y; // Target classes\n  vector[N] x;                      // Observed predictor values\n  real<lower=0> sigma;              // User supplied standard deviation\n  int correct_sigma;                // How to handle sigma, see below.\n}\n\ntransformed data{\n  vector[N] x_st;\n  real Sigma;\n\n  // Standardize data\n  x_st = (x - mean(x)) / sd(x);\n\n  // Maybe remember to scale sigma accordingly\n  if (correct_sigma == 1) {\n    Sigma = sigma / sd(x);\n  } else {\n    Sigma = sigma;\n  }\n}\n\nparameters {\n  // Inferred means.\n  ordered[K] c;\n  simplex[K] p_c;\n}\n\nmodel {\n  // Prior\n  c ~ normal(0,1);\n  p_c ~ dirichlet(rep_vector(1,K));\n\n  // Likelihood\n  for (n in 1:N) {\n    target += normal_lpdf(x_st[n] | c[y[n]], Sigma);\n  }\n}\n\ngenerated quantities {\n  // Posterior predictive sample\n  vector[N] yrep;\n  // For each observation, posterior predictive mass of classes\n  array[N] vector[K] ppm;\n\n  for (n in 1:N) {\n    for (k in 1:K) {\n      ppm[n, k] = normal_lpdf(x_st[n] | c[k], Sigma);\n    }\n    ppm[n, ] = softmax(ppm[n, ]);\n    yrep[n] = categorical_rng(ppm[n, ]);\n  }\n}\n\n\n\n\nrun CmdStanR\nfit_1 <- tryCatch(\n  expr = {readRDS(paste(\"../../code/stan-models/fits/gmm_classifier_1_\",SEED,\".RDS\", sep=\"\"))},\n  error = function(e) {\n    fit <- gmm$sample(data = c(standata_gmm, list(correct_sigma = 0)),\n                      parallel_chains = 4,\n                      refresh = 0,\n                      seed = SEED,\n                      show_messages = F)\n    if (SAVE_FITS) {fit$save_object(\n      paste(\"../../code/stan-models/fits/gmm_classifier_1_\",SEED,\".RDS\", sep=\"\"))}\n    return(fit)},\n  finally = {message(\"Finished model 1.\")})\n\nfit_2 <- tryCatch(\n  expr = readRDS(paste(\"../../code/stan-models/fits/gmm_classifier_2_\",SEED,\".RDS\", sep=\"\")),\n  error = function(e) {\n    fit <- gmm$sample(data = c(standata_gmm, list(correct_sigma = 1)),\n               parallel_chains = 4,\n               refresh = 0,\n               seed = SEED,\n               show_messages = F)\n    if (SAVE_FITS) {fit$save_object(\n      paste(\"../../code/stan-models/fits/gmm_classifier_2_\",SEED,\".RDS\", sep=\"\"))}\n    return(fit)},\n  finally = {message(\"Finished model 2.\")})\n\n\n\n\nCode\np_1 <- matrix(colMeans(fit_1$draws(variables = \"ppm\", format = \"matrix\")), ncol = K)\np_2 <- matrix(colMeans(fit_2$draws(variables = \"ppm\", format = \"matrix\")), ncol = K)"
  },
  {
    "objectID": "case_studies/ordinal/ordinal.html#ppc",
    "href": "case_studies/ordinal/ordinal.html#ppc",
    "title": "Calibrarion of Ordinal Posterior Predictions",
    "section": "PPC",
    "text": "PPC\n\n\n\n\nCode\nppc_bars(y = as.numeric(c),\n         yrep = fit_1$draws(variables = \"yrep\",format = \"matrix\")) +\n  ggtitle(\"Model 1\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\n\n\nCode\nppc_bars(y = as.numeric(c),\n         yrep = fit_2$draws(variables = \"yrep\", format = \"matrix\")) +\n  ggtitle(\"Model 2\") +\n  theme(legend.position = \"bottom\") \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nfor (k in 1:(K - 1)) {\n  p1 <- plot_dotted_reliabilitydiag(\n    y = as.numeric(c <= k),\n    x = if (k != 1) pmin(1, rowSums(p_1[, 1:k])) else p_1[, k],\n    quantiles = K * N / 100,\n    dot_scale = .5) +\n    ggtitle(paste(\"Model 1: P(y <= \", k, \")\", sep=\"\"),\n            subtitle = \"1 dot = 100 observations\")\n  \n  print(p1)\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nfor (k in 1:(K - 1)) {\n  p2 <- plot_dotted_reliabilitydiag(\n    y = as.numeric(c <= k),\n    x = if (k != 1) pmin(1, rowSums(p_2[, 1:k])) else p_2[, k],\n    quantiles = K * N / 100,\n    dot_scale = .5) +\n    ggtitle(paste(\"Model 2: P(y <= \", k, \")\", sep=\"\"),\n            subtitle = \"1 dot = 100 observations\")\n  \n  print(p2)\n  }"
  },
  {
    "objectID": "case_studies/ordinal/bn_classifier.html",
    "href": "case_studies/ordinal/bn_classifier.html",
    "title": "PPC: Ordinal predictions",
    "section": "",
    "text": "Code\nlibrary(cmdstanr)\nlibrary(DirichletReg)\nlibrary(bayesplot)\nlibrary(ggplot2)\nlibrary(reliabilitydiag)\nlibrary(khroma)\n\n# Source for the modified reliability plot\nsource(\"../../code/helpers.R\")\n\ngood_theme <- bayesplot::theme_default(base_family = \"Sans\") + theme(\n  axis.text = element_text(colour = \"#666666\", size = 12),\n  axis.ticks = element_line(colour = \"#666666\"),\n  title = element_text(colour = \"#666666\", size = 16),\n  plot.subtitle = element_text(colour = \"#666666\", size = 14),\n  legend.text = element_text(colour = \"#666666\", size = 12),\n  legend.title = element_text(colour = \"#666666\", size = 14),\n  axis.line = element_line(colour = \"#666666\"))\n\ntheme_set(good_theme)\nbayesplot_theme_set(good_theme)\ncolor_scheme_set(scheme = c(unname(colour(\"vibrant\")(7)[c(3,2,5,4,1,6)])))\n\nscale_colour_discrete = scale_colour_vibrant\nscale_fill_discrete = scale_fill_vibrant\n\nSEED <- 236543\nset.seed(SEED)\nSAVE_FITS = TRUE\nSIM_IIRM = TRUE # whether to use the inferred parameter values from the paper."
  },
  {
    "objectID": "case_studies/ordinal/bn_classifier.html#parameters-of-interest",
    "href": "case_studies/ordinal/bn_classifier.html#parameters-of-interest",
    "title": "PPC: Ordinal predictions",
    "section": "Parameters of interest",
    "text": "Parameters of interest\n\n\nCode\ncolor_scheme_set(scheme = color(\"BuRd\")(13)[6:1])\nmcmc_areas(fit$draws(variables = \"pU\", format = \"matrix\")) + vline_at(v = pU, colour = \"#666666\")\n\n\n\n\n\n\n\nCode\nmcmc_areas(fit$draws(variables = \"pE\", format = \"matrix\")[,-1]) + vline_at(v = pE[-1], colour = \"#666666\")"
  },
  {
    "objectID": "case_studies/ordinal/bn_classifier.html#population-parameters",
    "href": "case_studies/ordinal/bn_classifier.html#population-parameters",
    "title": "PPC: Ordinal predictions",
    "section": "Population parameters",
    "text": "Population parameters\nFor some reason, the authors also model the frequencies of the different observation categories in the population. These are recovered quite well.\n\n\nCode\nmcmc_areas(fit$draws(variables = \"pA\", format = \"matrix\")) + vline_at(v = pA, colour = \"#666666\")\n\n\n\n\n\n\n\nCode\nmcmc_areas(fit$draws(variables = \"pS\", format = \"matrix\")) + vline_at(v = pS, colour = \"#666666\")"
  },
  {
    "objectID": "case_studies/continuous/kde_with_discontinuities.html",
    "href": "case_studies/continuous/kde_with_discontinuities.html",
    "title": "Continuous Predictive Distribution",
    "section": "",
    "text": "Imports & options\nlibrary(\"bayesplot\")\nlibrary(\"cmdstanr\")\nlibrary(\"ggplot2\")\nlibrary(\"ggtrace\")\nlibrary(\"khroma\")\n\n\n# Source for the modified reliability plot\nsource(\"../../code/helpers.R\")\n\ngood_theme <- bayesplot::theme_default(base_family = \"Sans\") + theme(\n  axis.text = element_text(colour = \"#666666\", size = 12),\n  axis.ticks = element_line(colour = \"#666666\"),\n  title = element_text(colour = \"#666666\", size = 16),\n  plot.subtitle = element_text(colour = \"#666666\", size = 14),\n  legend.text = element_text(colour = \"#666666\", size = 12),\n  legend.title = element_text(colour = \"#666666\", size = 14),\n  axis.line = element_line(colour = \"#666666\"))\n\ntheme_set(good_theme)\nbayesplot_theme_set(good_theme)\ncolor_scheme_set(scheme = c(unname(colour(\"vibrant\")(7)[c(3,2,5,4,6,1)])))\n\nscale_colour_discrete = scale_colour_vibrant\nscale_fill_discrete = scale_fill_vibrant\n\nSEED <- 236543\nset.seed(SEED)\n\n\n\n\nData generation\nn_rep <- 10\nN <- 250\nfreq_na <- 0.1\nx <- rnorm(N, 1, .5)\nx[rbinom(N, 1, freq_na) == 1] <- 0\nmu_0 <- 0\nnu <- 1\nalpha <- 1\nbeta <- 1\n\nalpha_post <- alpha + N / 2\nbeta_post <- beta + 0.5 * (N - 1) * var(x) +\n  (N * nu * (mean(x) - mu_0) ** 2) / (2 * (nu + N))\n\nsd_post <- sqrt(1 / rgamma(n_rep, alpha_post, beta_post))\nnu_post <- nu + N\nmu_post <- rnorm(n_rep, nu * mu_0 + sum(x) / (nu * N), sd = sd_post / sqrt(nu_post) )\n\nx_post <- c(replicate(N, rnorm(n_rep, mu_post, sd_post)))\nrep_id <- rep(c(1:n_rep), each = N)\n\n\n\n\nCode\np_dens <- ppc_dens_overlay(x, matrix(x_post, nrow = n_rep))\np_dots <- ggplot() +\n  stat_dots(aes(x = x),\n            quantiles = 100,\n            fill = \"transparent\",\n            colour = layer_data(p_dens, 2L)$colour[1]) +\n  stat_density(aes(x = x),\n               geom = \"line\",\n               colour = layer_data(p_dens, 2L)$colour[1]) +\n  xlab(\"\")\np_hist <- ggplot() +\n  geom_histogram(aes(x = x),\n                 colour = layer_data(p_dens, 2L)$colour[1],\n                 fill = layer_data(p_dens, 2L)$colour[1],\n                 alpha = .2)\n\n\n\n\nCode\npit <- function(x, fig_data, idx) {\n  kde <- fig_data[fig_data$group == idx, c(\"x\",\"y\")]\n  Kde <- list(x = kde$x, y = (kde$x[2] - kde$x[1]) * cumsum(kde$y))\n  sapply(x, function(x_i) Kde$y[which.max(Kde$x >= x_i)])\n}\n\n\n\n\nCode\np_ecdf <- ppc_pit_ecdf(pit = pit(x, layer_data(p_dens, 2L), 1), interpolate_adj = T)\nfor (idx in 1:n_rep) {\n  gg_data = data.frame(\n    PIT = seq(0,1,length.out = N),\n    ECDF = ecdf(pit(x_post[rep_id == idx], layer_data(p_dens), idx))(seq(0,1,length.out = N))\n    )\n  p_ecdf <- p_ecdf + geom_step(data = gg_data, aes(x = PIT, y = ECDF), colour = layer_data(p_dens)$colour[1], alpha = .7, linewidth = layer_data(p_dens)$linewidth[1])\n}\n\n\n\n\nCode\np_ecdfd <- ppc_pit_ecdf(pit = pit(x, layer_data(p_dens, 2L), 1), interpolate_adj = T, plot_diff = T)\nfor (idx in 1:n_rep) {\n  gg_data = data.frame(\n    PIT = seq(0,1,length.out = N),\n    ECDF = ecdf(pit(x_post[rep_id == idx], layer_data(p_dens), idx))(seq(0,1,length.out = N))\n    )\n  p_ecdfd <- p_ecdfd + geom_step(data = gg_data, aes(x = PIT, y = ECDF - PIT), colour = layer_data(p_dens)$colour[1], alpha = .7, linewidth = layer_data(p_dens)$linewidth[1])\n}\n\n\n\n\nCode\np_dens\n\n\n\n\n\nCode\np_ecdf\n\n\n\n\n\nCode\np_ecdfd\n\n\n\n\n\nCode\np_dots\n\n\n\n\n\nCode\np_hist\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  }
]