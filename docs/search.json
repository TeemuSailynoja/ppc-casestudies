[
  {
    "objectID": "case_studies/ordinal/ordinal.html",
    "href": "case_studies/ordinal/ordinal.html",
    "title": "Calibrarion of Ordinal Posterior Predictions",
    "section": "",
    "text": "Imports & options\nlibrary(\"bayesplot\")\nlibrary(\"cmdstanr\")\nlibrary(\"ggplot2\")\nlibrary(\"khroma\")\nlibrary(\"quartoExtra\")\n\n\n# Source for the modified reliability plot\nsource(\"../../code/helpers.R\")\n\ngood_theme <- bayesplot::theme_default(base_family = \"Sans\") + theme(\n  axis.text = element_text(colour = \"#666666\", size = 12),\n  axis.ticks = element_line(colour = \"#666666\"),\n  title = element_text(colour = \"#666666\", size = 16),\n  plot.subtitle = element_text(colour = \"#666666\", size = 14),\n  legend.text = element_text(colour = \"#666666\", size = 12),\n  legend.title = element_text(colour = \"#666666\", size = 14),\n  axis.line = element_line(colour = \"#666666\"))\n\ntheme_set(good_theme)\nbayesplot_theme_set(good_theme)\ncolor_scheme_set(scheme = c(unname(colour(\"vibrant\")(7)[c(3,2,5,4,1,6)])))\n\nscale_colour_discrete = scale_colour_vibrant\nscale_fill_discrete = scale_fill_vibrant\n\n\n# darkmode_theme_set(\n#     dark = ggthemes::theme_stata(scheme = \"s1rcolor\"),\n#     light = ggthemes::theme_stata(scheme = \"s1color\")\n# )\n\n\nSEED <- 236543\nset.seed(SEED)\nSAVE_FITS = TRUE\nThis notebook highlights posterior predictive visualizations when the posterior predictive distribution is ordinal.\nAs shown below, the ordinal nature of the predictions allows us to use the cumulative posterior predictive mass function to assess the calibration of the posterior."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Case Studies in Visual Posterior Predictive Checks",
    "section": "",
    "text": "Calibrarion of Ordinal Posterior Predictions\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 4, 2023\n\n\nTeemu Säilynoja\n\n\n\n\n\n\n  \n\n\n\n\nPPC Visualizations for Categorical Data\n\n\nPalmer Penguins\n\n\nCalibration plots for the easy tasks of identifying penguin species in the Palmer Penguins data set.\n\n\n\n\n\n\nJan 30, 2023\n\n\nTeemu Säilynoja\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "case_studies/categorical/categorical_palmer_penguins.html",
    "href": "case_studies/categorical/categorical_palmer_penguins.html",
    "title": "PPC Visualizations for Categorical Data",
    "section": "",
    "text": "Code\nlibrary(\"bayesplot\")\nlibrary(\"cmdstanr\")\nlibrary(\"ggplot2\")\nlibrary(\"khroma\")\nlibrary(\"quartoExtra\")\n\n\n# Source for the modified reliability plot\nsource(\"../../code/helpers.R\")\n\ngood_theme <- bayesplot::theme_default(base_family = \"Sans\") + theme(\n  axis.text = element_text(colour = \"#666666\", size = 12),\n  axis.ticks = element_line(colour = \"#666666\"),\n  title = element_text(colour = \"#666666\", size = 16),\n  plot.subtitle = element_text(colour = \"#666666\", size = 14),\n  legend.text = element_text(colour = \"#666666\", size = 12),\n  legend.title = element_text(colour = \"#666666\", size = 14),\n  axis.line = element_line(colour = \"#666666\"))\n\ntheme_set(good_theme)\nbayesplot_theme_set(good_theme)\ncolor_scheme_set(scheme = c(unname(colour(\"vibrant\")(7)[c(3,2,5,4,1,6)])))\n\nscale_colour_discrete = scale_colour_vibrant\nscale_fill_discrete = scale_fill_vibrant\n\nsource(\"../../code/helpers.R\")\n\nSAVE_MODEL = TRUE\n\n\nCalibration plots for the easy tasks of identifying penguin species in the Palmer Penguins data set.\n\nThe data\n\n\nCode\nif (FALSE) {\n  data(\"iris\")\n  X <- dplyr::select(na.omit(iris), -c(\"Species\"))\n  y <- as.numeric(iris$Species)\n} else {\n  library(palmerpenguins)\n  data(\"penguins\")\n  X <- na.omit(penguins)[, c(3,4,5,6)]\n  y <- as.factor(na.omit(penguins)$species)\n}\n\n\n\n\nCode\nggplot(X, aes(x = bill_length_mm, y = bill_depth_mm, colour = y)) +\n  geom_point() +\n  xlab(\"Bill length (mm)\") +\n  ylab(\"Bill depth (mm)\") +\n  labs(colour = \"Species\") +\n  legend_move(position = \"top\")\n\n\n\n\n\n\n\nThe model\n\n\nCode\nif (FALSE) {\n  # model directory contains the required model\n  # load precompiled model\n} else {\n  model_code  = \"\n  data {\n    int N; // number of observations\n    int D; // number of features\n    int N_classes; // number of classes\n    matrix [N, D] X; // observation data\n    array[N] int <lower = 1, upper = N_classes> y; // target values {1,..., N_classes}\n  }\n  \n  transformed data {\n    matrix[D + 1, N] X_stn;\n    X_stn[D + 1, ] = rep_row_vector(1, N);\n    for (d in 1:D) {\n      X_stn[d,] = to_row_vector((X[, d] - mean(X[, d])) / sd(X[, d]));\n    }\n  }\n  \n  parameters {\n    matrix[N_classes, D + 1] W;\n  }\n  \n  transformed parameters {\n    matrix[N_classes, N] Beta;\n    for (c in 1:N_classes) {\n      Beta[c, ] =  W[c, ] * X_stn;\n    }\n  }\n  \n  model {\n    for (d in 1:(D + 1)) {\n      for (c in 1:N_classes) {\n        target += normal_lpdf(W[c, d] | 0, 1);\n      }\n    }\n    for (n in 1:N) {\n      target += categorical_logit_lpmf(y[n] | Beta[,n]);\n    }\n  }\n  \n  generated quantities {\n    vector[N] yrep;\n    for (n in 1:N) {\n      yrep[n] = categorical_logit_rng(Beta[,n]);\n    }\n    matrix[N,N_classes] lpd;\n    for (n in 1:N) {\n      for (c in 1:N_classes) {\n        lpd[n, c] = categorical_logit_lpmf(c | Beta[,n]);\n      }\n    }\n  }\n  \"\n  model = cmdstan_model(write_stan_file(\n      model_code,\n      dir = if(SAVE_MODEL) \"../../code/stan-models\" else tempdir(),\n      basename = \"penguins_glm\",\n    ))\n}\n\n\n\n\nCode\nfit <- model$sample(\n  data = list(N = nrow(X),\n              D = ncol(X),\n              N_classes = length(unique(y)),\n              X = X,\n              y = as.numeric(y)),\n  parallel_chains = 4,\n  refresh = 0)\n\n\nRunning MCMC with 4 parallel chains...\n\nChain 1 finished in 5.9 seconds.\nChain 4 finished in 5.9 seconds.\nChain 3 finished in 6.2 seconds.\nChain 2 finished in 6.4 seconds.\n\nAll 4 chains finished successfully.\nMean chain execution time: 6.1 seconds.\nTotal execution time: 6.5 seconds.\n\n\n\n\nThe calibration\nThe common approach of plotting a bar char of the observations overlaid with posterior means and 95% confidence intervals only gives a crude idea of the calibration of the model predictions.\n\n\nCode\nppc_bars(as.numeric(y), fit$draws(variables = \"yrep\", format = \"matrix\")) +\n  scale_x_continuous(breaks = 1:3, labels = levels(y))\n\n\n\n\n\n\n\nCode\nplot_dotted_reliabilitydiag(x = exp(colMeans(fit$draws(variables = paste(paste(\"lpd[\", 1:nrow(X), sep=\"\"), \",1]\", sep=\"\"), format = \"matrix\"))), y = as.numeric(y == levels(y)[1]), quantiles = 20) + labs(title = paste(\"Calibration:\", levels(y)[1], \"vs. Others\"))\n\n\n\n\n\n\n\nCode\nplot_dotted_reliabilitydiag(x = exp(colMeans(fit$draws(variables = paste(paste(\"lpd[\", 1:nrow(X), sep=\"\"), \",2]\", sep=\"\"), format = \"matrix\"))), y = as.numeric(y == levels(y)[2]), quantiles = 20) + labs(title = paste(\"Calibration:\", levels(y)[2], \"vs. Others\"))\n\n\n\n\n\n\n\nCode\nplot_dotted_reliabilitydiag(x = exp(colMeans(fit$draws(variables = paste(paste(\"lpd[\", 1:nrow(X), sep=\"\"), \",3]\", sep=\"\"), format = \"matrix\"))), y = as.numeric(y == levels(y)[3]), quantiles = 20)  + labs(title = paste(\"Calibration:\", levels(y)[3], \"vs. Others\"))"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "case_studies/ordinal/ordinal.html#data-set",
    "href": "case_studies/ordinal/ordinal.html#data-set",
    "title": "Calibrarion of Ordinal Posterior Predictions",
    "section": "Data set",
    "text": "Data set\nBelow, I use synthetic data generated from observations from \\(K\\) Gaussians with varying means.\n\\[\\begin{align}\nx_n &\\sim \\mathcal N\\!\\!\\left(k, 0.5^2\\right), &\\text{for } n \\in\\{1,\\dots,N\\}\\\\\nk &\\sim \\text{Categorical}(\\theta_k),&\\\\\n\\theta_k &= \\frac 1 K, &\\text{for } k \\in \\{1, \\dots, K\\}.\n\\end{align}\\]\n\n\nData generation\nK <- 5\nN <- 1500\nsigma <- .5\nc <- sample(1:K, N, replace = T)\nx <- rnorm(N, c, sigma)\nstandata_gmm <- list(K = K,\n                     N = N,\n                     x = x,\n                     y = c,\n                     sigma = sigma)\n\n\n\n\nCode\nggplot(data.frame(standata_gmm)) +\n  geom_density(aes(x = x,\n                   colour = as.factor(y),\n                   fill = as.factor(y),\n                   group = as.factor(y)), alpha = .5) +\n  legend_none() +\n  xlab(\"\") + ylab(\"\") + ggtitle(paste(\"The data\", sep = \"\"))"
  },
  {
    "objectID": "case_studies/ordinal/ordinal.html#model",
    "href": "case_studies/ordinal/ordinal.html#model",
    "title": "Calibrarion of Ordinal Posterior Predictions",
    "section": "Model",
    "text": "Model\nThe data is fit with two models, both structured to first normalize the data and then fit a GMM with K = 5`\n\n\nRead model code\ngmm <- cmdstan_model(\"../../code/stan-models/gmm_classifier.stan\")\ngmm\n\n\ndata {\n  int<lower=2> K;                   // Number of classes\n  int<lower=0> N;                   // Total number of observations\n  array[N] int<lower=1, upper=K> y; // Target classes\n  vector[N] x;                      // Observed predictor values\n  real<lower=0> sigma;              // User supplied standard deviation\n  int correct_sigma;                // How to handle sigma, see below.\n}\n\ntransformed data{\n  vector[N] x_st;\n  real Sigma;\n\n  // Standardize data\n  x_st = (x - mean(x)) / sd(x);\n\n  // Maybe remember to scale sigma accordingly\n  if (correct_sigma == 1) {\n    Sigma = sigma / sd(x);\n  } else {\n    Sigma = sigma;\n  }\n}\n\nparameters {\n  // Inferred means.\n  ordered[K] c;\n  simplex[K] p_c;\n}\n\nmodel {\n  // Prior\n  c ~ normal(0,1);\n  p_c ~ dirichlet(rep_vector(1,K));\n\n  // Likelihood\n  for (n in 1:N) {\n    target += normal_lpdf(x_st[n] | c[y[n]], Sigma);\n  }\n}\n\ngenerated quantities {\n  // Posterior predictive sample\n  vector[N] yrep;\n  // For each observation, posterior predictive mass of classes\n  array[N] vector[K] ppm;\n\n  for (n in 1:N) {\n    for (k in 1:K) {\n      ppm[n, k] = normal_lpdf(x_st[n] | c[k], Sigma);\n    }\n    ppm[n, ] = softmax(ppm[n, ]);\n    yrep[n] = categorical_rng(ppm[n, ]);\n  }\n}\n\n\n\n\nrun CmdStanR\nfit_1 <- tryCatch(\n  expr = {readRDS(paste(\"../../code/stan-models/fits/gmm_classifier_1_\",SEED,\".RDS\", sep=\"\"))},\n  error = function(e) {\n    fit <- gmm$sample(data = c(standata_gmm, list(correct_sigma = 0)),\n                      parallel_chains = 4,\n                      refresh = 0,\n                      seed = SEED,\n                      show_messages = F)\n    if (SAVE_FITS) {fit$save_object(\n      paste(\"../../code/stan-models/fits/gmm_classifier_1_\",SEED,\".RDS\", sep=\"\"))}\n    return(fit)},\n  finally = {message(\"Finished model 1.\")})\n\nfit_2 <- tryCatch(\n  expr = readRDS(paste(\"../../code/stan-models/fits/gmm_classifier_2_\",SEED,\".RDS\", sep=\"\")),\n  error = function(e) {\n    fit <- gmm$sample(data = c(standata_gmm, list(correct_sigma = 1)),\n               parallel_chains = 4,\n               refresh = 0,\n               seed = SEED,\n               show_messages = F)\n    if (SAVE_FITS) {fit$save_object(\n      paste(\"../../code/stan-models/fits/gmm_classifier_2_\",SEED,\".RDS\", sep=\"\"))}\n    return(fit)},\n  finally = {message(\"Finished model 2.\")})\n\n\n\n\nCode\np_1 <- matrix(colMeans(fit_1$draws(variables = \"ppm\", format = \"matrix\")), ncol = K)\np_2 <- matrix(colMeans(fit_2$draws(variables = \"ppm\", format = \"matrix\")), ncol = K)"
  },
  {
    "objectID": "case_studies/ordinal/ordinal.html#ppc",
    "href": "case_studies/ordinal/ordinal.html#ppc",
    "title": "Calibrarion of Ordinal Posterior Predictions",
    "section": "PPC",
    "text": "PPC\n\n\n\n\nCode\nppc_bars(y = as.numeric(c),\n         yrep = fit_1$draws(variables = \"yrep\",format = \"matrix\")) +\n  ggtitle(\"Model 1\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\n\n\nCode\nppc_bars(y = as.numeric(c),\n         yrep = fit_2$draws(variables = \"yrep\", format = \"matrix\")) +\n  ggtitle(\"Model 2\") +\n  theme(legend.position = \"bottom\") \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nfor (k in 1:(K - 1)) {\n  p1 <- plot_dotted_reliabilitydiag(\n    y = as.numeric(c <= k),\n    x = if (k != 1) pmin(1, rowSums(p_1[, 1:k])) else p_1[, k],\n    quantiles = K * N / 100,\n    dot_scale = .5) +\n    ggtitle(paste(\"Model 1: P(y <= \", k, \")\", sep=\"\"),\n            subtitle = \"1 dot = 100 observations\")\n  \n  print(p1)\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nfor (k in 1:(K - 1)) {\n  p2 <- plot_dotted_reliabilitydiag(\n    y = as.numeric(c <= k),\n    x = if (k != 1) pmin(1, rowSums(p_2[, 1:k])) else p_2[, k],\n    quantiles = K * N / 100,\n    dot_scale = .5) +\n    ggtitle(paste(\"Model 2: P(y <= \", k, \")\", sep=\"\"),\n            subtitle = \"1 dot = 100 observations\")\n  \n  print(p2)\n  }"
  }
]